{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def maybe_download_and_extract(dest_directory, url):\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    file_name = 'cifar-100-binary.tar.gz'\n",
    "    file_path = os.path.join(dest_directory, file_name)\n",
    "    # if have not downloaded yet\n",
    "    if not os.path.exists(file_path):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r%.1f%%' % \n",
    "                (float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()  # flush the buffer\n",
    "\n",
    "    print('>> Downloading %s ...' % file_name)\n",
    "    file_path, _ = urllib.request.urlretrieve(url, file_path, _progress)\n",
    "    file_size = os.stat(file_path).st_size\n",
    "    print('\\r>> Total %d bytes' % file_size)\n",
    "    extracted_dir_path = os.path.join(dest_directory, 'cifar-10-batches-bin')\n",
    "    if not os.path.exists(extracted_dir_path):\n",
    "    # Open for reading with gzip compression, then extract all\n",
    "        tarfile.open(file_path, 'r:gz').extractall(dest_directory)\n",
    "    print('>> Done')\n",
    "\n",
    "# <1 x label> <3072 x pixel>\n",
    "DATA_URL = 'http://www.cs.toronto.edu/~kriz/cifar-100-binary.tar.gz'\n",
    "DEST_DIRECTORY = 'dataset/cifar10'\n",
    "DATA_DIRECTORY = DEST_DIRECTORY + '/cifar-10-batches-bin'\n",
    "\n",
    "IMAGE_HEIGHT = 32\n",
    "IMAGE_WIDTH = 32\n",
    "IMAGE_DEPTH = 3\n",
    "\n",
    "# 圖片尺寸 24\n",
    "IMAGE_SIZE_CROPPED = 24\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "# 10個類別\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Label 只有一個字節\n",
    "LABEL_BYTES = 1\n",
    "\n",
    "# (IMAGE_HEIGHT) * (IMAGE_WIDTH) * (IMAGE_DEPTH)\n",
    "IMAGE_BYTES = 32 * 32 * 3\n",
    "\n",
    "# 樣本數目\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 50000\n",
    "NUM_EXAMPLES_PER_EPOCH_FOR_EVAL = 10000\n",
    "\n",
    "# download it\n",
    "# maybe_download_and_extract(DEST_DIRECTORY, DATA_URL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib.data import FixedLengthRecordDataset, Iterator\n",
    "\n",
    "def cifar10_record_distort_parser(record):\n",
    "    ''' Parse the record into label, cropped and distorted image\n",
    "    -----\n",
    "    Args:\n",
    "        record: \n",
    "            a record containing label and image.\n",
    "    Returns:\n",
    "        label: \n",
    "            the label in the record.\n",
    "        image: \n",
    "            the cropped and distorted image in the record.\n",
    "    '''\n",
    "    # TODO1\n",
    "    \n",
    "    # 解碼器 \n",
    "    record_uint8 = tf.decode_raw(record, tf.uint8)\n",
    "    \n",
    "    label = tf.cast(tf.strided_slice(record_uint8, [0], [LABEL_BYTES]), tf.int32)\n",
    "    \n",
    "    depth_major = tf.reshape(\n",
    "      tf.strided_slice(record_uint8, [LABEL_BYTES],\n",
    "                       [LABEL_BYTES + IMAGE_BYTES]),\n",
    "      [IMAGE_DEPTH, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    \n",
    "    image = tf.transpose(depth_major, [1, 2, 0])\n",
    "    \n",
    "    float_image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    height = IMAGE_SIZE_CROPPED\n",
    "    width = IMAGE_SIZE_CROPPED\n",
    "    \n",
    "    distorted_image = tf.random_crop(float_image, [height, width, 3])\n",
    "    distorted_image = tf.image.random_flip_left_right(distorted_image)\n",
    "    distorted_image = tf.image.random_brightness(distorted_image, max_delta=63)\n",
    "    distorted_image = tf.image.random_contrast(\n",
    "      distorted_image, lower=0.2, upper=1.8)\n",
    "    # standardization: subtract off the mean and divide by the variance of the pixels\n",
    "    distorted_image = tf.image.per_image_standardization(distorted_image)\n",
    "    # Set the shapes of tensors.\n",
    "    distorted_image.set_shape([height, width, 3])\n",
    "    label.set_shape([1])\n",
    "    return label, distorted_image\n",
    "\n",
    "\n",
    "def cifar10_record_crop_parser(record):\n",
    "    ''' Parse the record into label, cropped image\n",
    "    -----\n",
    "    Args:\n",
    "        record: \n",
    "            a record containing label and image.\n",
    "    Returns:\n",
    "        label: \n",
    "            the label in the record.\n",
    "        image: \n",
    "            the cropped image in the record.\n",
    "    '''\n",
    "    # TODO2\n",
    "    record_uint8 = tf.decode_raw(record, tf.uint8)\n",
    "    \n",
    "    label = tf.cast(tf.strided_slice(record_uint8, [0], [LABEL_BYTES]), tf.int32)\n",
    "    \n",
    "    depth_major = tf.reshape(\n",
    "      tf.strided_slice(record_uint8, [LABEL_BYTES],\n",
    "                       [LABEL_BYTES + IMAGE_BYTES]),\n",
    "      [IMAGE_DEPTH, IMAGE_HEIGHT, IMAGE_WIDTH])\n",
    "    \n",
    "    image = tf.transpose(depth_major, [1, 2, 0])\n",
    "    \n",
    "    float_image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    height = IMAGE_SIZE_CROPPED\n",
    "    width = IMAGE_SIZE_CROPPED\n",
    "    \n",
    "    distorted_image = tf.random_crop(float_image, [height, width, 3])\n",
    "    distorted_image.set_shape([height, width, 3])\n",
    "    label.set_shape([1])\n",
    "    return label, distorted_image\n",
    "\n",
    "\n",
    "def cifar10_iterator(filenames, batch_size, cifar10_record_parser):\n",
    "    ''' Create a dataset and return a tf.contrib.data.Iterator \n",
    "    which provides a way to extract elements from this dataset.\n",
    "    -----\n",
    "    Args:\n",
    "        filenames: \n",
    "            a tensor of filenames.\n",
    "        batch_size: \n",
    "            batch size.\n",
    "    Returns:\n",
    "        iterator: \n",
    "            an Iterator providing a way to extract elements from the created dataset.\n",
    "        output_types: \n",
    "            the output types of the created dataset.\n",
    "        output_shapes: \n",
    "            the output shapes of the created dataset.\n",
    "    '''\n",
    "    record_bytes = LABEL_BYTES + IMAGE_BYTES\n",
    "    # (5) reader for cifar10 file format\n",
    "    dataset = FixedLengthRecordDataset(filenames, record_bytes)\n",
    "    # TODO3\n",
    "    # tips: use dataset.map with cifar10_record_parser(record)\n",
    "    #       output_types = dataset.output_types\n",
    "    #       output_shapes = dataset.output_shapes\n",
    "    \n",
    "    dataset = dataset.map(cifar10_record_parser,num_parallel_calls=16)\n",
    "\n",
    "    min_fraction_of_examples_in_queue = 0.4\n",
    "    min_queue_examples = int(\n",
    "        NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN * min_fraction_of_examples_in_queue)\n",
    "    \n",
    "    dataset = dataset.repeat()\n",
    "    batch_dataset = dataset.batch(batch_size)\n",
    "\n",
    "    \n",
    "    iterator = batch_dataset.make_one_shot_iterator()\n",
    "    output_types = batch_dataset.output_types\n",
    "    output_shapes = batch_dataset.output_shapes\n",
    "    return iterator, output_types, output_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-4fe2dade0ff3>:101: FixedLengthRecordDataset.__init__ (from tensorflow.contrib.data.python.ops.readers) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.FixedLengthRecordDataset`.\n",
      "Tensor(\"IteratorGetNext:1\", shape=(?, 24, 24, 3), dtype=float32)\n",
      "Tensor(\"IteratorGetNext:0\", shape=(?, 1), dtype=int32)\n",
      "Shape of cropped image: (128, 24, 24, 3)\n",
      "Shape of label: (128,)\n",
      "WARNING:tensorflow:From <ipython-input-3-bf02861b319a>:44: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_or_create_global_step\n"
     ]
    }
   ],
   "source": [
    "model_hps_cifar = tf.contrib.training.HParams(\n",
    "  image_size = IMAGE_SIZE_CROPPED,\n",
    "  batch_size = BATCH_SIZE,\n",
    "  num_classes = NUM_CLASSES,\n",
    "  num_training_example = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN,\n",
    "  num_epoch_per_decay = 350.0,\n",
    "  init_lr = 0.1,\n",
    "  moving_average_decay = 0.9999,\n",
    "  ckpt_dir = './model/'\n",
    ")\n",
    "\n",
    "tf.reset_default_graph()\n",
    "# data_batch_0.bin ~ data_batch_5\n",
    "training_files = [\n",
    "    os.path.join(DATA_DIRECTORY, 'data_batch_%d.bin' % i) for i in range(1, 6)]\n",
    "testing_files = [os.path.join(DATA_DIRECTORY, 'test_batch.bin')]\n",
    "\n",
    "filenames_train = tf.constant(training_files)\n",
    "filenames_test = tf.constant(testing_files)\n",
    "\n",
    "iterator_train, types, shapes = cifar10_iterator(filenames_train, BATCH_SIZE,\n",
    "                                                 cifar10_record_distort_parser)\n",
    "\n",
    "\n",
    "iterator_test,_,_ = cifar10_iterator(filenames_test, BATCH_SIZE,\n",
    "                                    cifar10_record_crop_parser)\n",
    "\n",
    "# use to handle training and testing\n",
    "handle = tf.placeholder(tf.string, shape=[])\n",
    "iterator = Iterator.from_string_handle(handle, types, shapes)\n",
    "labels_images_pairs = iterator.get_next()\n",
    "\n",
    "# CNN model\n",
    "model = CNN_Model(model_hps_cifar)\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    labels, images = labels_images_pairs\n",
    "    print(images)\n",
    "    print(labels)\n",
    "    labels = tf.reshape(labels, [BATCH_SIZE])\n",
    "    images = tf.reshape(\n",
    "      images, [BATCH_SIZE, IMAGE_SIZE_CROPPED, IMAGE_SIZE_CROPPED, IMAGE_DEPTH])\n",
    "    print('Shape of cropped image:', images.shape)\n",
    "    print('Shape of label:', labels.shape)\n",
    "with tf.variable_scope('model'):\n",
    "    logits = model.inference(images)\n",
    "# train\n",
    "global_step = tf.contrib.framework.get_or_create_global_step()\n",
    "total_loss = model.loss(logits, labels)\n",
    "train_op = model.train(total_loss, global_step)\n",
    "# test\n",
    "top_k_op = tf.nn.in_top_k(logits, labels, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of epoch 1: 1519.412231\n",
      "loss of epoch 2: 1187.492188\n",
      "loss of epoch 3: 967.885376\n",
      "loss of epoch 4: 810.788757\n",
      "loss of epoch 5: 698.386597\n",
      "loss of epoch 6: 617.807861\n",
      "loss of epoch 7: 553.512634\n",
      "loss of epoch 8: 509.955994\n",
      "loss of epoch 9: 473.897217\n",
      "loss of epoch 10: 452.237976\n",
      "Done\n",
      "CPU times: user 2h 1min 51s, sys: 12min 10s, total: 2h 14min 2s\n",
      "Wall time: 35min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TODO4:\n",
    "# 1. train the CNN model 10 epochs\n",
    "# 2. show the loss per epoch\n",
    "# 3. get the accuracy of this 10-epoch model\n",
    "# 4. measure the time using '%%time' instruction\n",
    "# tips:\n",
    "# use placeholder handle to determine if training or testing. \n",
    "\n",
    "# op for training\n",
    "NUM_EPOCH = 10\n",
    "NUM_BATCH_PER_EPOCH = NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN // BATCH_SIZE\n",
    "ckpt_dir = './model/'\n",
    "\n",
    "# train\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    train_handle = sess.run(iterator_train.string_handle())\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    if (ckpt and ckpt.model_checkpoint_path):\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        # assume the name of checkpoint is like '.../model.ckpt-1000'\n",
    "        gs = int(ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1])\n",
    "        sess.run(tf.assign(global_step, gs))\n",
    "    else:\n",
    "        # no checkpoint found\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    loss = []\n",
    "    \n",
    "    for i in range(NUM_EPOCH):\n",
    "        _loss = []\n",
    "        for _ in range(NUM_BATCH_PER_EPOCH):\n",
    "            l, _ = sess.run([total_loss, train_op],feed_dict={handle: train_handle})\n",
    "            _loss.append(l)\n",
    "        loss_this_epoch = np.sum(_loss)\n",
    "        gs = global_step.eval()\n",
    "        print('loss of epoch %d: %f' % (gs / NUM_BATCH_PER_EPOCH, loss_this_epoch))\n",
    "        loss.append(loss_this_epoch)\n",
    "        saver.save(sess, ckpt_dir + 'model.ckpt', global_step=gs)\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n",
    "  \n",
    "    print('Done')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-3900\n",
      "Accurarcy: 4447/9984 = 0.445413\n",
      "CPU times: user 46.9 s, sys: 2.28 s, total: 49.2 s\n",
      "Wall time: 8.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "variables_to_restore = model.ema.variables_to_restore()\n",
    "saver = tf.train.Saver(variables_to_restore)\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    test_handle = sess.run(iterator_test.string_handle())\n",
    "    ckpt = tf.train.get_checkpoint_state(ckpt_dir)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "    # assume the name of checkpoint is like '.../model.ckpt-1000'\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    num_iter = NUM_EXAMPLES_PER_EPOCH_FOR_EVAL // BATCH_SIZE\n",
    "    total_sample_count = num_iter * BATCH_SIZE\n",
    "    true_count = 0\n",
    "    for _ in range(num_iter):\n",
    "        predictions = sess.run(top_k_op,feed_dict={handle: test_handle})\n",
    "        true_count += np.sum(predictions)\n",
    "    print('Accurarcy: %d/%d = %f' % (true_count, total_sample_count,\n",
    "                                     true_count / total_sample_count))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
